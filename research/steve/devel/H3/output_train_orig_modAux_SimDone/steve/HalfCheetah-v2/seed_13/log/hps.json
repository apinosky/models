ROOT GPU: 0
{'output_root': 'devel/output_train_orig_modAux_base_SimDone', 'save_model_path': 'checkpoints', 'log_path': 'log', 'agent_config': {'count': 1, 'batch_size': 1, 'reload_every_n': 1, 'full_random_n': 10000}, 'evaluator_config': {'count': 0, 'batch_size': 1}, 'policy_config': {'algo': 'ddpg', 'hidden_dim': 128, 'explore_chance': 0.05, 'batch_size': 512, 'replay_size': 1000000, 'frames_before_learning': 10000, 'log_every_n': 500, 'epoch_every_n': 500,  'backup_every_n': 2500000, 'frames_per_update': 0.25, 'policy_lr': 3e-4, 'value_lr': 3e-4, 'layers': [4,4], 'bayesian': {'ensemble_size': 4, 'train_sample_count': 4, 'eval_sample_count': 4}, 'value_expansion': {'rollout_len': 3, 'steve_reweight': True}}, 'model_config': {'transition_hidden_dim': 512, 'aux_hidden_dim': 128, 'batch_size': 512, 'replay_size': 1000000, 'frames_before_learning': 10000, 'log_every_n': 500, 'epoch_every_n': 500, 'backup_every_n': 2500000, 'pretrain_n': 10000, 'frames_per_update': 0.25, 'model_lr': 3e-4, 'layers': [8,4], 'bayesian': {'transition': {'ensemble_size': 4, 'train_sample_count': 4, 'eval_sample_count': 4}, 'reward': {'ensemble_size': 4, 'train_sample_count': 4, 'eval_sample_count': 4}}}, 'env': {'name': 'HalfCheetah-v2', 'obs_dims': [17], 'action_dim': 6, 'reward_scale': 1.0, 'discount': 0.99, 'max_frames': 1000}, 'name': 'steve', 'resume': False, 'seed': 13, 'original_config': True, 'no_done': True}